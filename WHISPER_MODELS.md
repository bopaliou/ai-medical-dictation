# üé§ Mod√®les Whisper disponibles

## üìã Mod√®les Whisper.cpp (format GGML)

Whisper.cpp utilise des mod√®les au format GGML (quantifi√©s). Voici les mod√®les disponibles :

### Mod√®les disponibles (par taille et qualit√©)

| Mod√®le | Taille | Qualit√© | Vitesse | RAM requise | Usage recommand√© |
|--------|--------|---------|---------|-------------|------------------|
| **tiny** | ~75 MB | ‚≠ê‚≠ê | ‚ö°‚ö°‚ö°‚ö°‚ö° | ~1 GB | Tests rapides, d√©veloppement |
| **base** | ~142 MB | ‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö°‚ö° | ~1 GB | **Actuel** - Bon √©quilibre |
| **small** | ~466 MB | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö°‚ö° | ~2 GB | Production, meilleure qualit√© |
| **medium** | ~1.5 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö°‚ö° | ~5 GB | Haute qualit√©, audio complexe |
| **large** | ~3.1 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ö° | ~10 GB | Qualit√© maximale |

### Mod√®le actuellement configur√©

**Mod√®le actuel :** `ggml-base.bin`
- **Chemin :** `${WSL_HOME}/whisper.cpp/models/ggml-base.bin`
- **Variable d'environnement :** `WHISPER_MODEL_PATH`

## üîß Configuration

### Modifier le mod√®le utilis√©

#### Option 1 : Variable d'environnement (recommand√©)

Ajoutez dans votre fichier `.env` :

```bash
# Mod√®le Whisper √† utiliser
WHISPER_MODEL_PATH=/home/bopaliou/whisper.cpp/models/ggml-small.bin
```

#### Option 2 : Modifier le code

Dans `backend/services/transcriptionLocal.js`, ligne 237 :

```javascript
let whisperModelPath = process.env.WHISPER_MODEL_PATH || `${wslHome}/whisper.cpp/models/ggml-base.bin`;
```

Changez `ggml-base.bin` par le mod√®le souhait√© :
- `ggml-tiny.bin` - Plus rapide, moins pr√©cis
- `ggml-base.bin` - **Actuel** - Bon √©quilibre
- `ggml-small.bin` - Meilleure qualit√©
- `ggml-medium.bin` - Haute qualit√©
- `ggml-large.bin` - Qualit√© maximale

## üì• T√©l√©chargement des mod√®les

### M√©thode 1 : Script de t√©l√©chargement (recommand√©)

Dans WSL, naviguez vers le dossier whisper.cpp :

```bash
cd ~/whisper.cpp
./models/download-ggml-model.sh base    # Pour base
./models/download-ggml-model.sh small  # Pour small
./models/download-ggml-model.sh medium # Pour medium
./models/download-ggml-model.sh large  # Pour large
./models/download-ggml-model.sh tiny   # Pour tiny
```

### M√©thode 2 : T√©l√©chargement manuel

Les mod√®les sont disponibles sur Hugging Face :
- **Tiny :** https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-tiny.bin
- **Base :** https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-base.bin
- **Small :** https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-small.bin
- **Medium :** https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-medium.bin
- **Large :** https://huggingface.co/ggerganov/whisper.cpp/resolve/main/ggml-large.bin

T√©l√©chargez dans : `~/whisper.cpp/models/`

## üéØ Recommandations par cas d'usage

### D√©veloppement / Tests
- **Mod√®le :** `tiny` ou `base`
- **Raison :** Rapide, suffisant pour les tests

### Production (qualit√© standard)
- **Mod√®le :** `base` (actuel) ou `small`
- **Raison :** Bon √©quilibre qualit√©/vitesse

### Production (haute qualit√©)
- **Mod√®le :** `small` ou `medium`
- **Raison :** Meilleure pr√©cision pour la transcription m√©dicale

### Production (qualit√© maximale)
- **Mod√®le :** `large`
- **Raison :** Meilleure pr√©cision, mais plus lent et gourmand en RAM

## üìä Comparaison des performances

### Temps de transcription (approximatif)

Pour un fichier audio de 1 minute :

| Mod√®le | Temps CPU | Temps GPU |
|--------|-----------|-----------|
| tiny | ~5-10s | ~1-2s |
| base | ~15-20s | ~2-3s |
| small | ~30-40s | ~5-8s |
| medium | ~60-90s | ~10-15s |
| large | ~120-180s | ~20-30s |

### Pr√©cision (WER - Word Error Rate)

| Mod√®le | WER (approximatif) |
|--------|-------------------|
| tiny | ~15-20% |
| base | ~10-15% |
| small | ~8-12% |
| medium | ~6-10% |
| large | ~5-8% |

## üîç V√©rifier le mod√®le install√©

Dans WSL :

```bash
ls -lh ~/whisper.cpp/models/
```

Vous devriez voir les fichiers `.bin` des mod√®les t√©l√©charg√©s.

## ‚öôÔ∏è Configuration actuelle

**Fichier de configuration :** `backend/services/transcriptionLocal.js`

**Ligne 237 :**
```javascript
let whisperModelPath = process.env.WHISPER_MODEL_PATH || `${wslHome}/whisper.cpp/models/ggml-base.bin`;
```

**Mod√®le par d√©faut :** `ggml-base.bin`

**Chemin par d√©faut :** `${WSL_HOME}/whisper.cpp/models/ggml-base.bin`

## üí° Astuce

Pour tester diff√©rents mod√®les sans modifier le code, utilisez la variable d'environnement `WHISPER_MODEL_PATH` dans votre `.env` :

```bash
# Pour utiliser small au lieu de base
WHISPER_MODEL_PATH=/home/bopaliou/whisper.cpp/models/ggml-small.bin
```

Puis red√©marrez le serveur backend.

---

**Document g√©n√©r√© automatiquement**
